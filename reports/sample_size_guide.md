# A/B 테스트 표본 크기 계산 가이드

## 📊 주요 발견사항

### 현재 A/B 테스트 결과 분석

**관찰된 결과**:
- Group A (Control) CTR: 78.08%
- Group B (ML Model) CTR: 74.03%
- 차이: -4.05%p (Group B가 낮음)

**통계적 유의성 검증**:
- 4.05%p 차이를 감지하려면: **1,525명/그룹** 필요
- 현재 샘플: 511명 (Group A), 489명 (Group B)
- **결론**: 현재 샘플(1,000명)은 **부족함** ❌

---

## 🎯 권장 표본 크기

### 시나리오 1: 5% 상대적 개선 감지 (기본)

**목표**: ML 모델이 5% 더 나은 성능을 보이는지 확인

| 지표 | 필요 샘플 (그룹당) |
|------|-------------------|
| CTR | 1,984명 |
| 구매 전환율 | **10,565명** ⭐ |
| 만족도 | 513명 |

**권장**: **10,565명/그룹** (총 21,130명)
- 가장 보수적인 추정 (구매 전환율 기준)

---

### 시나리오 2: 2% 상대적 개선 감지 (민감)

**목표**: 작은 효과도 감지

| 지표 | 필요 샘플 (그룹당) |
|------|-------------------|
| CTR | 12,815명 |
| 구매 전환율 | **65,664명** ⭐ |
| 만족도 | 3,204명 |

**권장**: **65,664명/그룹** (총 131,328명)
- 매우 큰 샘플 필요

---

### 시나리오 3: 90% 검정력 (높은 신뢰도)

**목표**: 5% 개선을 90% 확률로 감지

| 지표 | 필요 샘플 (그룹당) |
|------|-------------------|
| CTR | 2,655명 |
| 구매 전환율 | **14,143명** ⭐ |
| 만족도 | 687명 |

**권장**: **14,143명/그룹** (총 28,286명)

---

## 📈 표본 크기 결정 요인

### 1. 기준 비율 (Baseline Rate)

현재 시스템 성능:
- CTR: 75%
- 구매 전환율: 37.5% (CTR의 50% 가정)

### 2. 최소 감지 효과 (Minimum Detectable Effect)

감지하고자 하는 최소 개선:
- **5% 상대적 개선**: 75% → 78.75% (3.75%p)
- **2% 상대적 개선**: 75% → 76.5% (1.5%p)

### 3. 통계적 파라미터

- **유의수준 (α)**: 0.05 (5%)
  - Type I Error (False Positive) 확률
  - 실제로는 차이가 없는데 있다고 판단할 확률

- **검정력 (Power)**: 0.80 (80%)
  - 1 - Type II Error (False Negative)
  - 실제로 차이가 있을 때 이를 감지할 확률

---

## 🔍 현재 상황 분석

### 문제점

1. **샘플 크기 부족**
   - 현재: 1,000명
   - 필요: 최소 3,050명 (4.05%p 차이 감지용)
   - 부족분: 2,050명

2. **관찰된 효과가 역방향**
   - Group B가 Group A보다 **낮음** (-4.05%p)
   - ML 모델이 오히려 성능이 떨어짐

3. **통계적 유의성 없음**
   - p-value > 0.05
   - 우연에 의한 차이일 가능성

---

## 💡 권장사항

### 즉시 조치

1. **더 큰 샘플로 재실행**
   ```bash
   # 최소 3,000명 (그룹당 1,500명)
   python scripts/run_simulation.py --ab-test --users 3000 --llm 0 --seed 42
   ```

2. **목표에 따른 샘플 크기 선택**

   | 목표 | 샘플 크기 | 비고 |
   |------|-----------|------|
   | **빠른 검증** | 2,000명 | CTR만 확인 |
   | **표준 검증** | 10,000명 | 구매 전환율 포함 |
   | **엄격한 검증** | 20,000명 | 모든 지표 + 높은 검정력 |

### 장기 전략

1. **ML 모델 개선**
   - 현재 모델이 인기 상품보다 성능이 낮음
   - Feature engineering 재검토
   - 하이퍼파라미터 튜닝

2. **순차적 테스트 (Sequential Testing)**
   - 고정된 샘플 크기 대신 순차적으로 데이터 수집
   - 조기 중단 가능 (Early Stopping)

3. **다변량 테스트 (Multivariate Testing)**
   - 여러 변수 동시 테스트
   - 더 효율적인 학습

---

## 📊 표본 크기 계산 공식

### 비율(Proportion)에 대한 공식

```
n = [(Z_α/2 + Z_β)² × 2p(1-p)] / (p₂ - p₁)²

여기서:
- Z_α/2: 유의수준에 대한 Z-score (α=0.05 → 1.96)
- Z_β: 검정력에 대한 Z-score (power=0.80 → 0.84)
- p: 평균 비율 = (p₁ + p₂) / 2
- p₁: Control 그룹 비율
- p₂: Test 그룹 비율
```

### 평균(Mean)에 대한 공식

```
n = 2 × [(Z_α/2 + Z_β) × σ / δ]²

여기서:
- σ: 표준편차
- δ: 최소 감지 차이
```

---

## 🚀 실행 예시

### 예시 1: 표준 시나리오 (10,000명)

```bash
python scripts/run_simulation.py --ab-test --users 10000 --llm 0 --seed 42
```

**예상 결과**:
- 5% 개선을 80% 확률로 감지 가능
- 구매 전환율까지 신뢰할 수 있는 결과

### 예시 2: 빠른 검증 (2,000명)

```bash
python scripts/run_simulation.py --ab-test --users 2000 --llm 0 --seed 42
```

**예상 결과**:
- CTR 차이만 신뢰할 수 있음
- 구매 전환율은 참고용

### 예시 3: 엄격한 검증 (20,000명)

```bash
python scripts/run_simulation.py --ab-test --users 20000 --llm 0 --seed 42
```

**예상 결과**:
- 모든 지표에 대해 높은 신뢰도
- 90% 검정력 달성

---

## 📝 결론

**현재 상황**:
- 1,000명 샘플은 **부족함**
- ML 모델이 인기 상품보다 **성능 낮음**
- 통계적으로 **유의미하지 않음**

**권장 조치**:
1. **최소 3,000명**으로 재실행 (현재 차이 감지용)
2. **10,000명** 추천 (5% 개선 감지용)
3. ML 모델 개선 후 재테스트

**장기 목표**:
- ML 모델 성능 개선
- 더 큰 샘플로 정기적 테스트
- 순차적 테스트 도입

---

**생성일**: 2026-01-15
**도구**: `scripts/calculate_sample_size.py`
**통계 기준**: α=0.05, power=0.80
